{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JLDC/hugging-face-pipeline/blob/master/hugging_face_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this line only on Colab, it installs the transformers package\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "shoM7PKX-2Vi"
      },
      "id": "shoM7PKX-2Vi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "62209bb6-569c-4636-b993-431394ab6074",
      "metadata": {
        "tags": [],
        "id": "62209bb6-569c-4636-b993-431394ab6074"
      },
      "source": [
        "# Hugging Face ðŸ¤—\n",
        "___\n",
        "\n",
        "We have now learned about APIs and how to use them. In particular, we have seen how to use APIs to obtain data from web sources, but APIs are much more powerful than this. For instance, Google, Microsoft, Amazon, and others let you access some of their deep learning models through an API. While this can be very useful to get your business started quickly, it's generally fairly pricy and can be somewhat difficult to set up. Due to this, we decided to show what you can expect from such APIs by showing you Hugging Face models.\n",
        "\n",
        "[Hugging Face(https://huggingface.co/) is an AI community which provides many pre-trained deep learning models. From computer vision to sentiment classification, they have it all. In fact, they also provide an API, but it is not free.\n",
        "\n",
        "The main difference between Hugging Face and some API like Google Vision is that with Hugging Face, **the model runs on your machine**, whereas, with Google Vision, you make use of their servers, i.e., you will need a fairly powerful machine to run Hugging Face models, whereas you could make use of Google Vision on any device, as long as it can connect to their API.\n",
        "\n",
        "Hugging Face allows to make nice examples in a notebook that you can play with, this would not be doable with any other deep learning API that I know of."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e8a8dbd-04df-425e-8834-d6ec14216dde",
      "metadata": {
        "id": "3e8a8dbd-04df-425e-8834-d6ec14216dde"
      },
      "source": [
        "___\n",
        "## Transformers\n",
        "\n",
        "Introduced in the seminal paper of [Vaswani et al. (2017)](https://arxiv.org/abs/1706.03762), Transformers are state-of-the-art machine learning models for sequence-based tasks (note: a vision-based task can often be stated as a sequence-based task as well, i.e., there are so called *vision transformers*).\n",
        "\n",
        "Transformers are typically fairly complex. To simplify greatly, we can think of them as sequence-based models that primarily use [self-attention](https://en.wikipedia.org/wiki/Attention_(machine_learning)) to propagate information along the time dimension. This notebook will not delve into the inner workings of transformers. Instead, it will provide you with a few very simple examples to illustrate how powerful transformers can be on a flurry of tasks.\n",
        "\n",
        "[Hugging Face](https://huggingface.co/) provides access to pre-trained transformer models, making it easy to run intricate AI models in a few lines of code. \n",
        "\n",
        "### Inference with pre-trained models\n",
        "\n",
        "For now, we will focus on how to use ðŸ¤— Transformers for inference. In deep learning, when we talk about *inference*, we mean *putting the learned capabilities of the model to work*. I.e., training the model does not belong to inference.\n",
        "\n",
        "Hugging Face provides the `pipeline` function for inference with their pre-trained models. The `pipeline` function can accommodate many different types of tasks, amongst others:\n",
        "\n",
        "+ Image classification\n",
        "+ Sentiment analysis\n",
        "+ Speech recoginition\n",
        "+ Text generation\n",
        "+ Text summarization\n",
        "+ Translation\n",
        "+ Visual question answering\n",
        "\n",
        "This notebook only provides some examples of the `pipeline` function with the goal to show how easy it is to use complex AI models. As with the other notebooks, we suggest you play around with the codes and try things out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "830fc16d-44b8-4f1e-b5e4-afad8fcefb53",
      "metadata": {
        "id": "830fc16d-44b8-4f1e-b5e4-afad8fcefb53"
      },
      "outputs": [],
      "source": [
        "# Import the pipeline function from the transformers module\n",
        "from transformers import pipeline, set_seed\n",
        "\n",
        "# Import further modules to display images from URLs\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "# Regular expressions to clean text\n",
        "import re\n",
        "\n",
        "# Helper to read an image from URL\n",
        "get_image_from_url = lambda url: Image.open(BytesIO(requests.get(url).content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed7d5101-ed83-4d31-b8f0-6bb7b23ce354",
      "metadata": {
        "id": "ed7d5101-ed83-4d31-b8f0-6bb7b23ce354"
      },
      "source": [
        "#### Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "169097a4-cf39-492d-a28e-8528730a0898",
      "metadata": {
        "id": "169097a4-cf39-492d-a28e-8528730a0898"
      },
      "outputs": [],
      "source": [
        "# Load a pre-trained model for sentiment-analysis (text-classification)\n",
        "sentiment_classifier = pipeline(\n",
        "    task=\"sentiment-analysis\", \n",
        "    model=\"siebert/sentiment-roberta-large-english\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56bb086b-32ae-436d-b0a0-6fcfc69ee2c5",
      "metadata": {
        "id": "56bb086b-32ae-436d-b0a0-6fcfc69ee2c5"
      },
      "outputs": [],
      "source": [
        "# Running the model on a single sentence is as easy as it gets!\n",
        "sentiment_classifier(\"I had so much fun in this data science class!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deabcdae-f649-4da3-9c4f-cd10788b0f97",
      "metadata": {
        "id": "deabcdae-f649-4da3-9c4f-cd10788b0f97"
      },
      "source": [
        "The sentiment classifier always outputs a list of dictionaries, where the items have a **label** key and a **score** key. The label is either **POSITIVE** or **NEGATIVE** and the score is closer to 1 if the model is *confident about the chosen label* and close to zero otherwise.\n",
        "\n",
        "The output is a list of dictionaries, because we can also pass a list of sentences to classify!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aa34638-1a4b-4b24-8dee-4291fa994baa",
      "metadata": {
        "id": "0aa34638-1a4b-4b24-8dee-4291fa994baa"
      },
      "outputs": [],
      "source": [
        "# Define some sentences to classify\n",
        "sentences = [\n",
        "    \"This data science class was fairly difficult.\",\n",
        "    \"It was a lot to process.\",\n",
        "    \"I didn't know how to feel about the bootcamp before the break, but now I really like data science!\",\n",
        "    \"I didn't really understand anything but it was fun.\",\n",
        "    \"I could have spent my time better.\"\n",
        "]\n",
        "# Classify the sentences\n",
        "sentiment_classifier(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e7a7d0e-6be1-4f33-97e0-a1129b5ca528",
      "metadata": {
        "id": "5e7a7d0e-6be1-4f33-97e0-a1129b5ca528"
      },
      "source": [
        "Pretty impressive, don't you think? Even when the sentence structure is very similar, transformers are often able to correctly extract the meaning, see the example below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf1a330d-25d4-4976-8ace-6226d66520ca",
      "metadata": {
        "id": "cf1a330d-25d4-4976-8ace-6226d66520ca"
      },
      "outputs": [],
      "source": [
        "# Define some very 'similar' sequences in structure to see how the classifier does\n",
        "sentences = [\n",
        "    \"This is not an elegant piece of code, it's a horrible hack.\",\n",
        "    \"This is not a horrible hack, it's an elegant piece of code.\"\n",
        "]\n",
        "# Classify the sentences\n",
        "sentiment_classifier(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bee3e8d5-3c16-462e-ac43-de22db94d2d3",
      "metadata": {
        "id": "bee3e8d5-3c16-462e-ac43-de22db94d2d3"
      },
      "source": [
        "#### Image classification\n",
        "\n",
        "Of course, classifying text as negative or positive is not the only thing we can do with transformers. What about **image classification**?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6713162-e058-44a8-95fe-63c8afd40e11",
      "metadata": {
        "id": "b6713162-e058-44a8-95fe-63c8afd40e11"
      },
      "outputs": [],
      "source": [
        "# Use a pre-trained model for image classification\n",
        "image_classifier = pipeline(\n",
        "    task=\"image-classification\", \n",
        "    model=\"google/vit-base-patch16-224\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a01ade36-5337-43ce-8a16-69f36bb78bb1",
      "metadata": {
        "id": "a01ade36-5337-43ce-8a16-69f36bb78bb1"
      },
      "outputs": [],
      "source": [
        "# Replace the URL with any image you would like to classify\n",
        "img_url = \"https://cdn.download.ams.birds.cornell.edu/api/v1/asset/302473191/1800\"\n",
        "get_image_from_url(img_url).resize((200, 150)) # Display the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d21934fc-159f-485e-bbc0-1532c1cd6df3",
      "metadata": {
        "id": "d21934fc-159f-485e-bbc0-1532c1cd6df3"
      },
      "outputs": [],
      "source": [
        "# Classify the image (note that we can directly pass the URL, no need for PIL)\n",
        "image_classifier(img_url) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1182aeb-03c4-46c4-923f-5f165cd401fa",
      "metadata": {
        "id": "f1182aeb-03c4-46c4-923f-5f165cd401fa"
      },
      "source": [
        "As you can see from the above classification, Google's vision transformer is really confident about this image being a Chickadee, and it is correct! But this was not very difficult, perhaps we can try something more confusing..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "327a0044-7951-4fa8-aa0b-d12b9977356f",
      "metadata": {
        "id": "327a0044-7951-4fa8-aa0b-d12b9977356f"
      },
      "outputs": [],
      "source": [
        "# Replace the URL with any image you would like to classify\n",
        "img_url = \"https://cdn.shopify.com/s/files/1/1832/0821/files/catshark.jpg?v=1649869148\"\n",
        "get_image_from_url(img_url).resize((200, 200)) # Display the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d35d1982-5fc5-44c2-bd45-9d7c2f5f82ea",
      "metadata": {
        "id": "d35d1982-5fc5-44c2-bd45-9d7c2f5f82ea"
      },
      "outputs": [],
      "source": [
        "# Classify the image (note that we can directly pass the URL, no need for PIL)\n",
        "image_classifier(img_url) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28020249-da28-4691-a24b-afe9763950e5",
      "metadata": {
        "id": "28020249-da28-4691-a24b-afe9763950e5"
      },
      "source": [
        "Even if our cat is dressed up as a shark, Google's vision transformer is able to recognize it, although it's much less confident in the classification."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "980fbdfe-3a75-42c2-8245-7dae96a9a01a",
      "metadata": {
        "id": "980fbdfe-3a75-42c2-8245-7dae96a9a01a"
      },
      "source": [
        "#### Visual question answering\n",
        "Oh, and we can also ask our transformers questions about the image!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d46a0f28-8cb6-4de3-916d-5d5940d5a3a5",
      "metadata": {
        "id": "d46a0f28-8cb6-4de3-916d-5d5940d5a3a5"
      },
      "outputs": [],
      "source": [
        "# Use a pre-trained model for visual question answering\n",
        "question_answerer = pipeline(\n",
        "    task=\"vqa\",\n",
        "    model=\"dandelin/vilt-b32-finetuned-vqa\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c124b811-e2c5-4c9e-9594-d1a8f44fd12b",
      "metadata": {
        "id": "c124b811-e2c5-4c9e-9594-d1a8f44fd12b"
      },
      "outputs": [],
      "source": [
        "# Ask the model a question about our image\n",
        "question_answerer(image=img_url, question=\"What is the cat wearing?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cbe1fff-0fe1-4c74-9be1-1c25fb297922",
      "metadata": {
        "id": "9cbe1fff-0fe1-4c74-9be1-1c25fb297922"
      },
      "source": [
        "#### Text summarization\n",
        "Transformers can also be used for text summarization, take the following examples which summarizes some recent news articles.\n",
        "\n",
        "I have collected three recent articles from [CNN](https://edition.cnn.com/articles) into text files in `articles/`:\n",
        "\n",
        "+ [`articles/lottery.txt`](https://raw.githubusercontent.com/JLDC/hugging-face-pipeline/master/articles/lottery.txt)\n",
        "+ [`articles/plane_crash.txt`](https://raw.githubusercontent.com/JLDC/hugging-face-pipeline/master/articles/plane_crash.txt)\n",
        "+ [`articles/havard_museum.txt`](https://raw.githubusercontent.com/JLDC/hugging-face-pipeline/master/articles/havard_museum.txt)\n",
        "\n",
        "If you want to assess how well the summarizer is performing, go have a look at the short articles in plaintext."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f38283c9-1aca-4bc3-8f03-6d0ebb790e05",
      "metadata": {
        "id": "f38283c9-1aca-4bc3-8f03-6d0ebb790e05"
      },
      "outputs": [],
      "source": [
        "# Use a pre-trained model for text summarization\n",
        "summarizer = pipeline(\n",
        "    task=\"summarization\",\n",
        "    model=\"sshleifer/distilbart-cnn-12-6\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the content of the article variable to access another of the three articles\n",
        "article = \"plane_crash\"\n",
        "# Get the article from GitHub and clean special characters\n",
        "url = f\"https://raw.githubusercontent.com/JLDC/hugging-face-pipeline/master/articles/{article}.txt\"\n",
        "content = re.sub(\"\\s+\", \" \", requests.get(url).text)\n",
        "content # Display the content of the article"
      ],
      "metadata": {
        "id": "lUUbkxSbA97u"
      },
      "id": "lUUbkxSbA97u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14b2769f-ad5b-4987-b640-2bb938d96492",
      "metadata": {
        "id": "14b2769f-ad5b-4987-b640-2bb938d96492"
      },
      "outputs": [],
      "source": [
        "# Summarize the above content\n",
        "summarizer(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a196b6e-993a-42e3-bd60-ff3a2506791f",
      "metadata": {
        "id": "9a196b6e-993a-42e3-bd60-ff3a2506791f"
      },
      "source": [
        "#### Text generation\n",
        "Keeping the best for last, let's look at text generation. We can also use transformers to generate text by passing the beginning of a sentence, it can generate random continuations of the initial sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f45bc81-2703-495f-bdfc-d26656afd9e4",
      "metadata": {
        "id": "2f45bc81-2703-495f-bdfc-d26656afd9e4"
      },
      "outputs": [],
      "source": [
        "# Use a pre-trained model for text summarization\n",
        "generator = pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=\"gpt2\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e11fad7-540f-4f38-96ee-d2beabaeb368",
      "metadata": {
        "id": "3e11fad7-540f-4f38-96ee-d2beabaeb368"
      },
      "outputs": [],
      "source": [
        "set_seed(99) # Comment this out to get different propositions\n",
        "\n",
        "# Generate 3 continutation of this sentence\n",
        "results = generator(\"In this data science class, we\", num_return_sequences=3,\n",
        "                   max_length=50, early_stopping=True)\n",
        "\n",
        "# Print results\n",
        "for result in results:\n",
        "    print(result[\"generated_text\"])\n",
        "    print(\"-\"*50) # Print a separating line"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4437a3b-1ce1-4f73-9ebc-63b3c9434a15",
      "metadata": {
        "id": "d4437a3b-1ce1-4f73-9ebc-63b3c9434a15"
      },
      "source": [
        "Pretty impressive! Be careful, however, these pre-trained models often come with a strong bias. This is because they have been trained on existing texts, and, in a sense, they take over the bias that was entailed in those texts. Here are two illustrative examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a648e99a-c159-4522-b470-a280387c675e",
      "metadata": {
        "id": "a648e99a-c159-4522-b470-a280387c675e"
      },
      "outputs": [],
      "source": [
        "# Set the seed and generate a text for a male protagonist\n",
        "set_seed(2)\n",
        "results = generator(\"The man is working as a\", \n",
        "                    max_length=10, num_return_sequences=10)\n",
        "\n",
        "# Print results\n",
        "for result in results:\n",
        "    print(result[\"generated_text\"])\n",
        "    print(\"-\"*50) # Print a separating line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa603019-4676-4bb9-828b-98c019d4a2a9",
      "metadata": {
        "id": "fa603019-4676-4bb9-828b-98c019d4a2a9"
      },
      "outputs": [],
      "source": [
        "# Set the seed and generate a text for a female protagonist\n",
        "set_seed(2)\n",
        "results = generator(\"The woman is working as a\", \n",
        "                    max_length=10, num_return_sequences=10)\n",
        "\n",
        "# Print results\n",
        "for result in results:\n",
        "    print(result[\"generated_text\"])\n",
        "    print(\"-\"*50) # Print a separating line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdbd38ca-1c6d-48bc-b14e-da652ac41dc2",
      "metadata": {
        "id": "bdbd38ca-1c6d-48bc-b14e-da652ac41dc2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}